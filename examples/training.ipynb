{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16af81850f057780",
   "metadata": {},
   "source": [
    "# DeepRacer Complete Pipeline Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6cc6198b704696",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing MinIO bucket: tcc-experiments\n",
      "Using existing MinIO bucket: tcc-experiments\n",
      "Using existing MinIO bucket: tcc-experiments\n",
      "Using existing MinIO bucket: tcc-experiments\n",
      "Using existing MinIO bucket: tcc-experiments\n",
      "Viewer pipeline logging configured to file: /tmp/viewer_pipeline.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/insightlab/miniconda3/envs/drfc/lib/python3.11/site-packages/gloe/functional.py:177: RuntimeWarning: Only one parameter is allowed on Transformers. Function 'setup_evaluation_env' has the following signature: (_, model_name: str, clone: bool = False, quiet: bool = False). To pass a complex data, use a complex type like named tuples, typed dicts, dataclasses or anything else.\n",
      "  warnings.warn(\n",
      "/home/insightlab/miniconda3/envs/drfc/lib/python3.11/site-packages/gloe/functional.py:177: RuntimeWarning: Only one parameter is allowed on Transformers. Function 'setup_upload_env' has the following signature: (_, source_model_name: str, target_model_name: Optional[str] = None, wipe: bool = False, force: bool = False). To pass a complex data, use a complex type like named tuples, typed dicts, dataclasses or anything else.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', module='.*paramiko.*')\n",
    "\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "from src.training_pipeline import train_pipeline, stop_training_pipeline\n",
    "from src.evaluation_pipeline import evaluate_pipeline, stop_evaluation_pipeline\n",
    "from src.loganalysis_pipeline import start_loganalysis_pipeline, stop_loganalysis_pipeline\n",
    "from src.upload_model_pipeline import upload_model_pipeline, download_model_pipeline\n",
    "from src.viewer_pipeline import start_viewer_pipeline, stop_viewer_pipeline\n",
    "\n",
    "from src.types.hyperparameters import HyperParameters\n",
    "from src.types.model_metadata import ModelMetadata\n",
    "from src.config import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7390673703d0b582",
   "metadata": {},
   "source": [
    "## 2. Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc093ea3a87c4a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a unique model name\n",
    "model_name = 'rl-deepracer-demo'\n",
    "\n",
    "# Create default hyperparameters and model metadata\n",
    "hyperparameters = HyperParameters()\n",
    "model_metadata = ModelMetadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfedd3608f3df109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HyperParameters(batch_size=64, beta_entropy=0.01, discount_factor=0.999, e_greedy_value=0.05, epsilon_steps=10000, exploration_type=<ExplorationType.CATEGORICAL: 'categorical'>, loss_type=<LossType.HUBER: 'huber'>, lr=0.0003, num_episodes_between_training=40, num_epochs=3, stack_size=1, term_cond_avg_score=100000, term_cond_max_episodes=100000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the hyperparameters\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6efa625cad6135b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelMetadata(action_space_type=<ActionSpaceType.CONTINUOUS: 'continuous'>, action_space=ContinuousActionSpace(steering_angle=SteeringAngle(high=30.0, low=-30.0), speed=Speed(high=4.0, low=1.0)), version=5, training_algorithm=<TrainingAlgorithm.PPO: 'clipped_ppo'>, neural_network=<NeuralNetwork.DEEP_CONVOLUTIONAL_NETWORK_SHALLOW: 'DEEP_CONVOLUTIONAL_NETWORK_SHALLOW'>, sensor=[<Sensor.FRONT_FACING_CAMERA: 'FRONT_FACING_CAMERA'>])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the model metadata\n",
    "model_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aeda5a8e1768361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params):\n",
    "    \"\"\"\n",
    "    Example of a reward function for DeepRacer.\n",
    "    \n",
    "    Args:\n",
    "        params (dict): Input parameters from the simulator\n",
    "        \n",
    "    Returns:\n",
    "        float: The reward value\n",
    "    \"\"\"\n",
    "    # Give a high reward by default\n",
    "    reward = 1.0\n",
    "    \n",
    "    # Get track parameters\n",
    "    all_wheels_on_track = params.get('all_wheels_on_track', True)\n",
    "    distance_from_center = params.get('distance_from_center', 0)\n",
    "    track_width = params.get('track_width', 1)\n",
    "    \n",
    "    # Calculate 3 markers that are at varying distances from the center line\n",
    "    marker_1 = 0.1 * track_width\n",
    "    marker_2 = 0.25 * track_width\n",
    "    marker_3 = 0.5 * track_width\n",
    "    \n",
    "    # Give higher reward if the car is closer to center line and vice versa\n",
    "    if distance_from_center <= marker_1:\n",
    "        reward = 1.0\n",
    "    elif distance_from_center <= marker_2:\n",
    "        reward = 0.5\n",
    "    elif distance_from_center <= marker_3:\n",
    "        reward = 0.1\n",
    "    else:\n",
    "        reward = 1e-3  # likely crashed/ close to off track\n",
    "        \n",
    "    # Penalize if the car goes off track\n",
    "    if not all_wheels_on_track:\n",
    "        reward = 1e-3\n",
    "        \n",
    "    return float(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b0e9d55b34174",
   "metadata": {},
   "source": [
    "## 3. Pipeline Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255de14139b2f1d7",
   "metadata": {},
   "source": [
    "### 3.1 Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "129ac34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to stop training stack...\n",
      "Targeting Run ID: 0\n",
      "Cleaning up previous run for project deepracer-0...\n",
      "Executing: docker compose -p deepracer-0 down --remove-orphans --volumes\n",
      "Stderr:\n",
      " Container deepracer-0-rl_coach-1  Stopping\n",
      " Container deepracer-0-robomaker-1  Stopping\n",
      " Container deepracer-0-robomaker-1  Stopped\n",
      " Container deepracer-0-robomaker-1  Removing\n",
      " Container deepracer-0-robomaker-1  Removed\n",
      " Container deepracer-0-redis-1  Stopping\n",
      " Container deepracer-0-redis-1  Stopped\n",
      " Container deepracer-0-redis-1  Removing\n",
      " Container deepracer-0-redis-1  Removed\n",
      " Container deepracer-0-rl_coach-1  Stopped\n",
      " Container deepracer-0-rl_coach-1  Removing\n",
      " Container deepracer-0-rl_coach-1  Removed\n",
      "\n",
      "Training stack stopped successfully.\n"
     ]
    }
   ],
   "source": [
    "# First stop any existing training\n",
    "stop_training_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d14691e9fccfcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training pipeline for model: rl-deepracer-demo, Run ID: 0\n",
      "Model prefix rl-deepracer-demo/ does not exist. Proceeding.\n",
      "Successfully uploaded custom_files/hyperparameters.json to bucket tcc-experiments\n",
      "Successfully uploaded custom_files/model_metadata.json to bucket tcc-experiments\n",
      "Successfully uploaded custom_files/reward_function.py to bucket tcc-experiments\n",
      "Data uploaded successfully to custom files\n",
      "Successfully copied custom_files/reward_function.py to rl-deepracer-demo/reward_function.py\n",
      "The reward function copied successfully to models folder at rl-deepracer-demo/reward_function.py\n",
      "Generating local training_params.yaml...\n",
      "Generated /tmp/dr/training-params-20250427220428.yaml, uploading to rl-deepracer-demo/training_params.yaml\n",
      "Successfully uploaded local file /tmp/dr/training-params-20250427220428.yaml to rl-deepracer-demo/training_params.yaml\n",
      "Verified: Training params file exists at rl-deepracer-demo/training_params.yaml\n",
      "Cleaned up local file: /tmp/dr/training-params-20250427220428.yaml\n",
      "Upload successfully the RoboMaker training configurations\n",
      "Loaded DR_* vars for model 'rl-deepracer-demo' into current process environment.\n",
      "Starting model training\n",
      "Attempting to start DeepRacer Docker stack...\n",
      "Cleaning up previous run for project deepracer-0...\n",
      "Executing: docker compose -p deepracer-0 down --remove-orphans --volumes\n",
      "Stderr:\n",
      "time=\"2025-04-27T22:04:28-03:00\" level=warning msg=\"Warning: No resource found to remove for project \\\"deepracer-0\\\".\"\n",
      "\n",
      "Pruning unused Docker resources...\n",
      "Executing: docker network prune -f\n",
      "Executing: docker system prune -f\n",
      "Stdout:\n",
      "Total reclaimed space: 0B\n",
      "\n",
      "Starting DeepRacer stack for project deepracer-0 with 1 workers...\n",
      "Network 'sagemaker-local' already exists.\n",
      "Created modified compose file with Redis at /tmp/docker-compose-training-redis-yu1g_n79.yml\n",
      "Using compose files: ['/tmp/docker-compose-training-redis-yu1g_n79.yml', '/home/insightlab/deepracer/drfc-manager/config/drfc-images/docker-compose-keys.yml', '/home/insightlab/deepracer/drfc-manager/config/drfc-images/docker-compose-endpoint.yml']\n",
      "ROBOMAKER_COMMAND set to: /opt/simapp/run.sh run distributed_training.launch\n",
      "Executing: docker compose -f /tmp/docker-compose-training-redis-yu1g_n79.yml -f /home/insightlab/deepracer/drfc-manager/config/drfc-images/docker-compose-keys.yml -f /home/insightlab/deepracer/drfc-manager/config/drfc-images/docker-compose-endpoint.yml -p deepracer-0 up -d --remove-orphans --force-recreate\n",
      "Stderr:\n",
      "time=\"2025-04-27T22:04:32-03:00\" level=warning msg=\"/home/insightlab/deepracer/drfc-manager/config/drfc-images/docker-compose-keys.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion\"\n",
      "time=\"2025-04-27T22:04:32-03:00\" level=warning msg=\"/home/insightlab/deepracer/drfc-manager/config/drfc-images/docker-compose-endpoint.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion\"\n",
      " Container deepracer-0-rl_coach-1  Creating\n",
      " Container deepracer-0-redis-1  Creating\n",
      " Container deepracer-0-rl_coach-1  Created\n",
      " Container deepracer-0-redis-1  Created\n",
      " Container deepracer-0-robomaker-1  Creating\n",
      " Container deepracer-0-robomaker-1  Created\n",
      " Container deepracer-0-redis-1  Starting\n",
      " Container deepracer-0-rl_coach-1  Starting\n",
      " Container deepracer-0-redis-1  Started\n",
      " Container deepracer-0-robomaker-1  Starting\n",
      " Container deepracer-0-rl_coach-1  Started\n",
      " Container deepracer-0-robomaker-1  Started\n",
      "\n",
      "Cleaned up temporary file /tmp/docker-compose-training-redis-yu1g_n79.yml\n",
      "Checking container status...\n",
      "Executing: docker compose -p deepracer-0 ps\n",
      "Stdout:\n",
      "NAME                      IMAGE                                              COMMAND                  SERVICE     CREATED         STATUS         PORTS\n",
      "deepracer-0-redis-1       redis:alpine                                       \"docker-entrypoint.s…\"   redis       7 seconds ago   Up 6 seconds   6379/tcp\n",
      "deepracer-0-rl_coach-1    awsdeepracercommunity/deepracer-simapp:5.3.3-gpu   \"/bin/bash -c 'pytho…\"   rl_coach    7 seconds ago   Up 6 seconds   \n",
      "deepracer-0-robomaker-1   awsdeepracercommunity/deepracer-simapp:5.3.3-gpu   \"/bin/bash -c '/opt/…\"   robomaker   7 seconds ago   Up 5 seconds   0.0.0.0:6900->5900/tcp, 0.0.0.0:6900->5900/tcp, [::]:6900->5900/tcp, [::]:6900->5900/tcp, 0.0.0.0:9080->8080/tcp, 0.0.0.0:9080->8080/tcp, [::]:9080->8080/tcp, [::]:9080->8080/tcp\n",
      "\n",
      "Executing: docker ps --filter label=com.docker.compose.project=deepracer-0 --filter label=com.docker.compose.service=robomaker --filter status=running -q\n",
      "Stdout:\n",
      "514d9df3480c\n",
      "\n",
      "Found running RoboMaker containers: 1\n",
      "Successfully started 1 RoboMaker workers.\n",
      "DeepRacer Docker stack started successfully.\n",
      "Docker stack started.\n",
      "Skipping log check.\n",
      "Training pipeline finished.\n"
     ]
    }
   ],
   "source": [
    "# Start training with our model configuration\n",
    "train_pipeline(\n",
    "    model_name=model_name,\n",
    "    hyperparameters=hyperparameters,\n",
    "    model_metadata=model_metadata,\n",
    "    reward_function=reward_function,\n",
    "    overwrite=True,\n",
    "    check_logs_after_start=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viewer-section",
   "metadata": {},
   "source": [
    "### 3.2 Viewer Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "start-viewer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the training process at: http://localhost:8101\n"
     ]
    }
   ],
   "source": [
    "result = start_viewer_pipeline(delay=0)\n",
    "print(f\"View the training process at: {result['viewer_url']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d558ee95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success', 'message': 'Viewer and proxy processes stopped.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_viewer_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "log-analysis-section",
   "metadata": {},
   "source": [
    "### 3.3 Log Analysis Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "start-log-analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting log analysis container...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Transformer.__call__() missing 1 required positional argument: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Start log analysis container\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m result = \u001b[43mstart_loganalysis_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m pprint(result)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# You can now access the Jupyter notebook at http://localhost:8888\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/deepracer/drfc-manager/src/loganalysis_pipeline.py:69\u001b[39m, in \u001b[36mstart_loganalysis_pipeline\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting log analysis container...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Use forward[None]() pattern like in training_pipeline\u001b[39;00m\n\u001b[32m     68\u001b[39m start_pipeline = forward[\u001b[38;5;28;01mNone\u001b[39;00m]() >> (\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[43mstart_log_analysis_container\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m >>\n\u001b[32m     70\u001b[39m     If(\u001b[38;5;28;01mlambda\u001b[39;00m result: result.get(\u001b[33m'\u001b[39m\u001b[33mstatus\u001b[39m\u001b[33m'\u001b[39m) == \u001b[33m'\u001b[39m\u001b[33msuccess\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     71\u001b[39m     .Then(echo(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLog analysis container started. Access Jupyter at: http://localhost:8888\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     72\u001b[39m     .Else(echo(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to start log analysis container.\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     73\u001b[39m )\n\u001b[32m     75\u001b[39m result = start_pipeline(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     76\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLog analysis pipeline completed.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Transformer.__call__() missing 1 required positional argument: 'data'"
     ]
    }
   ],
   "source": [
    "# Start log analysis container\n",
    "result = start_loganalysis_pipeline()\n",
    "pprint(result)\n",
    "\n",
    "# You can now access the Jupyter notebook at http://localhost:8888"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upload-download-section",
   "metadata": {},
   "source": [
    "### 3.4 Upload/Download Pipeline\n",
    "\n",
    "Let's assume we want to save our model under a different name to preserve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stop-training-for-upload",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's stop the training to ensure all model files are properly saved\n",
    "stop_training_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upload-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload (or copy) the model to a new location\n",
    "target_name = f\"{model_name}-backup\"\n",
    "result = upload_model_pipeline(\n",
    "    source_model_name=model_name,\n",
    "    target_model_name=target_name,\n",
    "    wipe=True,\n",
    "    force=True\n",
    ")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also download a model (in this case, our backup to a new name)\n",
    "result = download_model_pipeline(\n",
    "    source_model_name=target_name,\n",
    "    target_model_name=f\"{model_name}-restored\",\n",
    "    force=True\n",
    ")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation-section",
   "metadata": {},
   "source": [
    "### 3.5 Evaluation Pipeline\n",
    "\n",
    "Now let's evaluate the model to see how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stop-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop any existing evaluation\n",
    "stop_evaluation_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "start-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate our trained model\n",
    "result = evaluate_pipeline(\n",
    "    model_name=model_name,\n",
    "    quiet=False,\n",
    "    clone=False\n",
    ")\n",
    "pprint(result)\n",
    "\n",
    "# The evaluation is now running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "update-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's update the viewer to see the evaluation\n",
    "result = start_viewer_pipeline(update=True)\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-section",
   "metadata": {},
   "source": [
    "## 4. Cleanup\n",
    "\n",
    "When you're done, it's good practice to stop all services to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop all running services\n",
    "stop_training_pipeline()\n",
    "stop_evaluation_pipeline()\n",
    "stop_viewer_pipeline()\n",
    "stop_loganalysis_pipeline()\n",
    "\n",
    "print(\"All DeepRacer services have been stopped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
