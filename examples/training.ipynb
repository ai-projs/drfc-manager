{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16af81850f057780",
   "metadata": {},
   "source": [
    "# DeepRacer Complete Pipeline Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6cc6198b704696",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 22:27:56 - drfc - INFO - Using existing MinIO bucket: tcc-experiments\n",
      "2025-07-04 22:27:56 - drfc - INFO - Using existing MinIO bucket: tcc-experiments\n",
      "2025-07-04 22:27:56 - drfc - INFO - Using existing MinIO bucket: tcc-experiments\n",
      "2025-07-04 22:27:56 - drfc - INFO - Using existing MinIO bucket: tcc-experiments\n",
      "2025-07-04 22:27:56 - drfc - INFO - Using existing MinIO bucket: tcc-experiments\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing EnvVars for the first time\n"
     ]
    }
   ],
   "source": [
    "from drfc_manager.pipelines import (\n",
    "    train_pipeline, stop_training_pipeline, clone_pipeline,\n",
    "    start_viewer_pipeline, stop_viewer_pipeline,\n",
    "    start_metrics_pipeline, stop_metrics_pipeline\n",
    ")\n",
    "\n",
    "from drfc_manager.types.hyperparameters import HyperParameters\n",
    "from drfc_manager.types.model_metadata import ModelMetadata, DiscreteActionSpace\n",
    "from drfc_manager.types.env_vars import EnvVars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd61b279-82f7-497b-a59b-09d77b9a1aba",
   "metadata": {},
   "source": [
    "## 2. Environment Configuration (Optional)\n",
    "Set a value in the params only if you want override a default config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e70ca15a-9387-45f9-a40c-b1d965f100f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = EnvVars()\n",
    "#envs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7390673703d0b582",
   "metadata": {},
   "source": [
    "## 3. Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc093ea3a87c4a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HyperParameters(batch_size=64, beta_entropy=0.01, discount_factor=0.999, e_greedy_value=0.05, epsilon_steps=10000, exploration_type=<ExplorationType.CATEGORICAL: 'categorical'>, loss_type=<LossType.HUBER: 'huber'>, lr=0.0003, num_episodes_between_training=40, num_epochs=3, stack_size=1, term_cond_avg_score=100000, term_cond_max_episodes=100000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a unique model name\n",
    "model_name = 'rl-deepracer-sagemaker-v2'\n",
    "\n",
    "hyperparameters = HyperParameters()\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70be0185-b97c-4753-a6ba-a2e973f08e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelMetadata(action_space_type=<ActionSpaceType.CONTINUOUS: 'continuous'>, action_space=ContinuousActionSpace(steering_angle=SteeringAngle(high=30.0, low=-30.0), speed=Speed(high=4.0, low=1.0)), version=5, training_algorithm=<TrainingAlgorithm.PPO: 'clipped_ppo'>, neural_network=<NeuralNetwork.DEEP_CONVOLUTIONAL_NETWORK_SHALLOW: 'DEEP_CONVOLUTIONAL_NETWORK_SHALLOW'>, sensor=[<Sensor.FRONT_FACING_CAMERA: 'FRONT_FACING_CAMERA'>])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dasp1 = DiscreteActionSpace(steering_angle=-30, speed=0.6)\n",
    "dasp2 = DiscreteActionSpace(steering_angle=-15, speed=0.6)\n",
    "dasp3 = DiscreteActionSpace(steering_angle=-0, speed=0.6)\n",
    "dasp4 = DiscreteActionSpace(steering_angle=15, speed=0.6)\n",
    "dasp5 = DiscreteActionSpace(steering_angle=30, speed=0.6)\n",
    "action_spaces = [dasp1, dasp2, dasp3, dasp4, dasp5]\n",
    "\n",
    "# model_metadata = ModelMetadata(action_space_type=ActionSpaceType.DISCRETE, action_space=action_spaces)\n",
    "model_metadata = ModelMetadata()\n",
    "model_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aeda5a8e1768361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params):\n",
    "    '''\n",
    "    Example of penalize steering, which helps mitigate zig-zag behaviors\n",
    "    '''\n",
    "    \n",
    "    # Read input parameters\n",
    "    distance_from_center = params['distance_from_center']\n",
    "    track_width = params['track_width']\n",
    "    steering = abs(params['steering_angle']) # Only need the absolute steering angle\n",
    "\n",
    "    # Calculate 3 marks that are farther and father away from the center line\n",
    "    marker_1 = 0.1 * track_width\n",
    "    marker_2 = 0.25 * track_width\n",
    "    marker_3 = 0.5 * track_width\n",
    "\n",
    "    # Give higher reward if the car is closer to center line and vice versa\n",
    "    if distance_from_center <= marker_1:\n",
    "        reward = 1\n",
    "    elif distance_from_center <= marker_2:\n",
    "        reward = 0.5\n",
    "    elif distance_from_center <= marker_3:\n",
    "        reward = 0.1\n",
    "    else:\n",
    "        reward = 1e-3  # likely crashed/ close to off track\n",
    "\n",
    "    # Steering penality threshold, change the number based on your action space setting\n",
    "    ABS_STEERING_THRESHOLD = 15\n",
    "\n",
    "    # Penalize reward if the car is steering too much\n",
    "    if steering > ABS_STEERING_THRESHOLD:\n",
    "        reward *= 0.8\n",
    "\n",
    "    return float(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b0e9d55b34174",
   "metadata": {},
   "source": [
    "## 3. Pipeline Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255de14139b2f1d7",
   "metadata": {},
   "source": [
    "### 3.1 Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d14691e9fccfcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded successfully to custom files\n",
      "The reward function copied successfully to models folder at rl-deepracer-sagemaker-v2/reward_function.py\n",
      "Upload successfully the RoboMaker training configurations\n",
      "Starting model training\n",
      "Docker stack started.\n",
      "Skipping log check.\n"
     ]
    }
   ],
   "source": [
    "# Start training with our model configuration\n",
    "train_pipeline(\n",
    "    model_name=model_name,\n",
    "    hyperparameters=hyperparameters,\n",
    "    model_metadata=model_metadata,\n",
    "    reward_function=reward_function,\n",
    "    overwrite=True,\n",
    "    # env_vars=envs, # You can pass it or not, if you don't, the default values will be used\n",
    "    quiet=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30990808",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_training_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446fcdde",
   "metadata": {},
   "source": [
    "### 3.1.2 - Cloning your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ef8a131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function_base_reward(params):\n",
    "    \"\"\"\n",
    "    Example of a reward function for DeepRacer.\n",
    "    \n",
    "    Args:\n",
    "        params (dict): Input parameters from the simulator\n",
    "        \n",
    "    Returns:\n",
    "        float: The reward value\n",
    "    \"\"\"\n",
    "    # Give a high reward by default\n",
    "    reward = 1.0\n",
    "    \n",
    "    # ...\n",
    "        \n",
    "    return float(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38f484d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from drfc_manager.types.model_metadata import NeuralNetwork\n",
    "\n",
    "hyperparameters_base_reward = HyperParameters(batch_size=128)\n",
    "model_metadata_base_reward = ModelMetadata(neural_network=NeuralNetwork.DEEP_CONVOLUTIONAL_NETWORK_DEEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98fd80e0-0dfa-4379-94e6-41b05a420552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HyperParameters(batch_size=128, beta_entropy=0.01, discount_factor=0.999, e_greedy_value=0.05, epsilon_steps=10000, exploration_type=<ExplorationType.CATEGORICAL: 'categorical'>, loss_type=<LossType.HUBER: 'huber'>, lr=0.0003, num_episodes_between_training=40, num_epochs=3, stack_size=1, term_cond_avg_score=100000, term_cond_max_episodes=100000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters_base_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61e0ad88-8522-415a-be8e-9090594b3675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelMetadata(action_space_type=<ActionSpaceType.CONTINUOUS: 'continuous'>, action_space=ContinuousActionSpace(steering_angle=SteeringAngle(high=30.0, low=-30.0), speed=Speed(high=4.0, low=1.0)), version=5, training_algorithm=<TrainingAlgorithm.PPO: 'clipped_ppo'>, neural_network=<NeuralNetwork.DEEP_CONVOLUTIONAL_NETWORK_DEEP: 'DEEP_CONVOLUTIONAL_NETWORK_DEEP'>, sensor=[<Sensor.FRONT_FACING_CAMERA: 'FRONT_FACING_CAMERA'>])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metadata_base_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3057ebb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded successfully to custom files\n",
      "The reward function copied successfully to models folder at rl-deepracer-sagemaker-v2-1/reward_function.py\n",
      "Upload successfully the RoboMaker training configurations\n",
      "Starting model training\n",
      "Docker stack started.\n",
      "Skipping log check.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'rl-deepracer-sagemaker-v2-1'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone_pipeline(\n",
    "    model_name,\n",
    "    wipe_target=True,\n",
    "    custom_hyperparameters=hyperparameters_base_reward,\n",
    "    custom_model_metadata=model_metadata_base_reward,\n",
    "    custom_reward_function=reward_function_base_reward\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c53bfdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_training_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viewer-section",
   "metadata": {},
   "source": [
    "## 3.2 Viewer Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "start-viewer",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the training process at: http://localhost:8103. The proxy is http://localhost:8090\n"
     ]
    }
   ],
   "source": [
    "result = start_viewer_pipeline(delay=0)\n",
    "# print(result)\n",
    "print(f\"View the training process at: {result['viewer_url']}. The proxy is {result[\"proxy_url\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d558ee95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success', 'message': 'Viewer and proxy processes stopped.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_viewer_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93526b20",
   "metadata": {},
   "source": [
    "## 3.3 Grafana Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee6e4131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetricsResult(status='success', error=None, error_type=None, grafana_url='http://localhost:3000', credentials={'username': 'admin', 'password': 'admin'}, log_file='/tmp/drfc_logs/drfc_20250704_223838.log', message=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_metrics_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a35607a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetricsResult(status='success', error=None, error_type=None, grafana_url=None, credentials=None, log_file=None, message='Metrics stack stopped successfully')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_metrics_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drfc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
